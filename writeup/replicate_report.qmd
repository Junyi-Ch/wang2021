---
title: "Replication of Idiosyncratic Tower of Babel: Individual Differences in Word-Meaning Representation Increase as Word Abstractness Increases by Wang & Bi (2021, Psychological Science)"
author: "Junyi Chen (contact information)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

[No abstract is needed.]  Each replication project will have a straightforward, no frills report of the study and results.  These reports will be publicly available as supplementary material for the aggregate report(s) of the project as a whole.  Also, to maximize project integrity, the intro and methods will be written and critiqued in advance of data collection.  Introductions can be just 1-2 paragraphs clarifying the main idea of the original study, the target finding for replication, and any other essential information. You will likely contact the authors of the original study, so this should be professional and forward facing. It will NOT have a literature review -- that is in the original publication. You can write both the introduction and the methods in past tense.  

### Short Justification

My research interests centered around language development, learning, and processing. I chose this experiment because I would like to do studies on semantic network, word knowledge, and individual differences. I would like to eventually do this type of studies in children, and I am still trying to poke around to see what might work for my own project. I think this experiment is a good point to start
because it studies how adults differ in their representations of words, and how this depends on the abstractness of words. I would be able to learn specific ways of conducting the experiment and data analysis 
that will be useful for my own study in the future.

### Stimulus and Procedures

#### Stimuli
Stimuli consisted  of  90  written  Chinese words,  of  which  40 were  object  words  and  50  were words  without  explicit  external referents. Words without external referents varied in their  emotional  associations;  20  words  did  not  have emotional connotations,  and  30  were  emotionally  related words (e.g., violence). The list is included in the paper. 

#### Procedures
##### update for oct15th
* I plan to contact the authors for their data analysis and the task. I have also tried out building the task in jspsych, and it seems to work as described in the paper.
* I will try to use their availabel data (https://osf.io/cyusp/overview BehavioralSemanticDistanceMatrix ) to see if I can replicate the results using their data. 
* I plan to reduce the amount of words to decrease the experiment time for participants. Currently it is 1 hour and too long. 
* From what I can understand, their over pipeline is as followed:
  + Task:
    - 90 words displayed around a circular arena on a computer screen
    - subjects drag and drop words to arrange them spatially based on semantic similarity
    - Trial 1: All 90 words arranged, producing a 90 x 90 distance matrix.
    - subsequent trials: adaptively selected word subsets presented for arrangement depending on the original clusters, and subjects completed varying numbers of trials.
  + The adaptive selection process (the part I'm most unsure about)
    - The system maintains an evidence weight matrix for all word pairs. Then, then system finds the weakest evidence pair. Then it adds words by calculating the trial efficieny until adding a word's benefit is not larger than its cost. These words form a subset. 
  + Data Analysis:
    - Inter-Subject Correlation (ISC) Analysis: 
    Word representation: Each word represented as an 89-dimensional vector (its distances to all other words)
    Pairwise correlations: Pearson correlations computed between each pair of subjects' word vectors
    Fisher z-transformation: Applied to normalize correlation distributions
    Averaging: Mean correlation across all 190 subject pairs (20 subjects total)
    Result: ISC-behavior score for each word, indicating how consistently that word's semantic relationships are judged across subjects



##### Semantic Judgment Task
Subjects dragged and dropped words in a circular array on a computer screen, arranging them spatially close together or far apart  according  to  the  words’  semantic  distances. Participants do this through multiple trials where each trial contains a subset of the 90 words that were clustered together in a previous trial.

#### Challenges
One challenge for me would be to create this experiment in JsPsych, as I have little experience in coding through JsPsych. Another challenge would be the statistical analysis of the data, where they represented each word in a 89-dimensional space.

#### Link to original paper
https://github.com/Junyi-Ch/wang2021/blob/5d14173c206e148ecf507ae991633fdfdb4b7656/original_paper/wang-bi-2021-idiosyncratic-tower-of-babel-individual-differences-in-word-meaning-representation-increase-as-word.pdf

## Methods

### Power Analysis



### Planned Sample

Because this replication uses about 60% the number of words and only one arrangement per participant (less information per person about each word), I plan to increase the behavioral sample modestly from 20 to 30. I will stop data collection when 30 usable datasets are collected. A dataset is usable if the participant completes the arrangement and passes attention/comprehension checks.

Participants will be adults recruited from UCSD. Inclusion criteria: native speakers of Mandarin Chinese. Participants will receive course credit or monetary compensation.

### Materials

"Stimuli in our study consisted of 90 written Chinese words, of which 40 were object words and 50 were words without explicit external referents (see the Appendix). Object words varied in their sensory and motor attributes; they consisted of 10 animals (e.g., cat), 10 face or body parts (e.g., shoulder), and 20 artifacts such as tools and common household objects (e.g., microwave). Words without external referents varied in their emotional associations; 20 words did not have emotional connotations (i.e., “nonemotional nonobject” words, as determined by being rated as having low arousal [< 3] and being emotionally neutral [3.5–4.5] on 7-point scales by independent groups of college students; see below), and 30 were emotionally related words (e.g., violence)."

I will use a 63-word subset rather than the full 90 words. I will maintain the same types/categories and match mean familiarity and frequency (as closely as possible) across the subset categories.

### Procedure	

"Semantic distance-judgment task. The word-meaning representations were obtained using a multiarrangement paradigm (Kriegeskorte & Mur, 2012). In this paradigm, subjects dragged and dropped words in a circular array on a computer screen, arranging them spatially close together or far apart according to the words’ semantic distances (Fig. 1a). The task consisted of multiple trials. In the first trial, subjects had to arrange all 90 words, producing a 90 × 90 matrix containing Euclidean distances among all the words. In subsequent trials, subjects were shown adaptively selected word subsets that had been clustered together in previous trials, producing partial distance matrices. The task lasted for 1 hr, during which subjects completed various numbers of trials (M = 85, SD = 71, range = 24–284). The final distance measure for each subject was calculated as the weighted average of distance measures of their multiple arrangements. Multidimensional scaling was carried out to visualize individual semantic distance matrices (number of dimensions [ndim] = 2, type = interval) using the smacof package (de Leeuw & Mair, 2009) in the R programming environment (Version 4.0.0; R Core Team, 2020)."

I will follow the multi-arrangement paradigm reported in Wang & Bi (Kriegeskorte & Mur, 2012) but instead of many adaptive trials, each participant will perform a single full-set arrangement. (I haven't decided on this yet).

### Analysis Plan

Primary question: Do object words show higher intersubject consistency (ISC-behavior) than abstract words?

"To compute the word-level ISC in behavior for each subject, we represented each word as an 89-dimensional vector of its semantic distance with the remaining words. Pearson’s correlations of the word vector among each pair of subjects were then computed, Fisher z transformed, and averaged across 190 subject pairs (20 subjects in total) to obtain ISC-behavior data for each word. The standard error of the ISC for behavior was assessed in two approaches: (a) bootstrapping the subject set with replacement 10,000 times, which evaluated ISC robustness across subjects, and (b) bootstrapping the word set with replacement 10,000 times, which evaluated ISC robustness across words included for judgment." I will compute word-level ISC-behavior exactly as in Wang & Bi but using the reduced word set (N = 63).

Participants will be excluded if they do not pass attention checks, or if they have words that are unarranged during the experiment. 

**Clarify key analysis of interest here**  You can also pre-specify additional analyses you plan to do.

### Differences from Original Study

1. Number of words. Original: 90 words. Replication: 63 words (70%). Rationale: reduce participant burden and session length. Expected impact: fewer words reduces the number of observations at the word level (less power to detect word-level predictors) and reduces the dimensionality of word vectors (vectors of length 44 vs 89), which may change ISC estimates.

2. Number of trials. Original: multiarrangement adaptive procedure producing many arrangements per subject. Replication: single full arrangement per participant (to simplify implementation). Expected impact: the original used multiple arrangements per person and computed weighted averages across arrangements to stabilize distance estimates. Using just one arrangement per participant gives less within-subject sampling and will likely increase noise. 

3. Population differences. Original: Chinese college students in Beijing, native Chinese speakers. Our replication sample will be from our local subject pool in the US, and we will increase the number of participants. Expected impact: I don't expect this to impact the study since we are still testing native Mandarin speakers.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions

#### Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
